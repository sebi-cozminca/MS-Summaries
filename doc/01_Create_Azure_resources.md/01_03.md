---
title: '03: Agentic AI Inferencing with Azure Container Apps (Catalog Dev)'  
layout: default
nav_order: 3
parent: 'Lab summaries'
--- 

# Lab Metadata & Summary

**ID** 191959  
**Number:** LAB341  
**Name:** Agentic AI Inferencing with Azure Container Apps (Catalog Dev)  
**CloudSubscriptionPoolName:** Microsoft Event Subscription (CSS)  
**AllowSave:** True  
**CloudCredentialPoolAssignments:** NA  
**Additional licenses:** NA  

---

## Exercise Summary
### Exercise 0: Environment validation
- **Goal:** Confirm ACA resources, registry, and identity are in place for agentic inferencing.
- **Actions:** Review ACA apps, Dapr/components, managed identity and logging; validate container image availability.
- **Validation:** Sample request to the app returns 200; ACA logs show successful inference.

### Exercise 1: Containerize and deploy the model service
- **Goal:** Package a lightweight model server and deploy to ACA.
- **Actions:** Build/push image, configure CPU/GPU, revisions, autoscale, and secrets for model endpoint.
- **Validation:** `/healthz` and simple inference call succeed; revisions roll out cleanly.

### Exercise 2: Wire into an agentic pipeline
- **Goal:** Expose ACA endpoint to an agent (Azure AI Foundry / SK / MCP).
- **Actions:** Add the ACA tool to the agent, define action schema, and pass-grounded context to calls.
- **Validation:** Agent invokes ACA for tool use; traces show end‑to‑end latency and success rate.

### Exercise 3: Observability & cost
- **Goal:** Measure throughput, latency, and cost.
- **Actions:** Enable Log Analytics and Container App insights; set min/max replicas; run load test.
- **Validation:** Dashboards show target P50/P95; autoscale keeps SLOs with controlled cost.
